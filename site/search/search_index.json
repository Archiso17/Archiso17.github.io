{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Archiso17.github.io","text":"<p>Personal Notebooks</p>"},{"location":"#step-1","title":"Step 1","text":"<pre><code>add configuration\n</code></pre>"},{"location":"Boot-strapping%20k8s%20cluster/","title":"note 2","text":"<p>k8smaster IP: 192.168.17.17 MAC: 00:0c:29:dc:38:ff product_uuid: a9454d56-bca6-5f28-b127-a04dc9dc38ff</p> <p>k8admin K85@Adm1n-           </p> <p>k8sworker1: IP: 192.168.17.19 MAC: 00:0c:29:8b:bc:01 product_uuid: c2324d56-4359-cbc3-7a20-1178668bbc01</p> <p>k8worker K85w0rk3r@Adm1n-</p> <p>k8sworker2: IP: </p> <p>cred: k8worker K85w0rk3r@Adm1n-</p> <p>command :  sudo apt update -y &amp;&amp; sudo apt upgrade -y sudo apt install net-tools </p> <p>kubeadm init --control-plane-endpoint=k8smaster --upload-cert</p> <p>Prerequisites: 1. compatible Linux 2. Minimum 2CPU/2GB RAM 3. connectivity between all the  nodes in the cluster 4. unique hostname, mac address and product_uuid for each node     5. verify mac using : ip link / ifconfig -a     6. verify product_uuid : sudo cat /sys/class/dmi/id/product_uuid 5. Kubernetes uses these values to uniquely identify the nodes in the cluster 6. if these values are not unique: issue: https://github.com/kubernetes/kubeadm/issues/31 7. disable the swap : swapoff -a;sed -i '/swap/d' /etc/fstab 8. to view the swap: swapon -s or cat /etc/fstab swaopn  9. ![[Pasted image 20250211130646.png]]     ![[Pasted image 20250211130742.png]] 10. sysctl parameters config:     1. Linux kernel does not allow IPv4 packets to be routed between interfaces.      2. enable ipv4 packet forwarding:      ```bash</p>"},{"location":"Boot-strapping%20k8s%20cluster/#sysctl-params-required-by-setup-params-persist-across-reboots","title":"sysctl params required by setup, params persist across reboots","text":"<p>cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1  net.bridge.bridge-nf-call-iptables = 1 EOF</p>"},{"location":"Boot-strapping%20k8s%20cluster/#apply-sysctl-params-without-reboot","title":"Apply sysctl params without reboot","text":"<p>sudo sysctl --system</p> <pre><code>\n```bash\nsysctl net.ipv4.ip_forward\n</code></pre> <p>Load necessary kernel modules:</p> <pre><code>sudo modprobe overlay  \nsudo modprobe br_netfilter\n</code></pre> <ol> <li>Installing docker and container runtime interface</li> </ol> <pre><code>for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done\n</code></pre> <ol> <li>apt packages</li> </ol> <pre><code># Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add the repository to Apt sources:\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release &amp;&amp; echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt-get update\n</code></pre> <ol> <li>install docker</li> </ol> <pre><code>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre> <pre><code>systemctl enable docker\ndocker run hello-world\n\n</code></pre> <p>Installing kubernetes packages</p> <pre><code>sudo apt-get update\n# apt-transport-https may be a dummy package; if so, you can skip that package\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\n</code></pre> <p>downloading the public signing key:</p> <pre><code># If the directory `/etc/apt/keyrings` does not exist, it should be created before the curl command, read the note below.\n# sudo mkdir -p -m 755 /etc/apt/keyrings\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n\n</code></pre> <p>signed the packages with the key</p> <pre><code># This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list\necho 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list\n</code></pre> <p>installed the required package</p> <pre><code>sudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\nsudo apt-mark hold kubelet kubeadm kubectl\n</code></pre> <p>restart the kubelet service</p> <pre><code>sudo systemctl enable --now kubelet\n</code></pre> <p>disable the apparmor in ubuntu server.</p> <p>remove the cri from in /etc/containred/config.toml ![[Pasted image 20250211160630.png]]</p> <p>![[Pasted image 20250211115024.png]] ![[Pasted image 20250211155531.png]]</p> <p>kubeadm init --control-plane-endpoint=k8smaster --upload-certs</p> <p>o/p</p> <p>[init] Using Kubernetes version: v1.32.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action beforehand using 'kubeadm config images pull' W0211 10:50:23.611958    4323 checks.go:846] detected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm.It is recommended to use \"registry.k8s.io/pause:3.10\" as the CRI sandbox image. [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8smaster kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.17.17] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [k8smaster localhost] and IPs [192.168.17.17 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8smaster localhost] and IPs [192.168.17.17 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"super-admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\" [kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s [kubelet-check] The kubelet is healthy after 1.005820882s [api-check] Waiting for a healthy API server. This can take up to 4m0s [api-check] The API server is healthy after 10.001809691s [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: 289aead532d1508800f44452a24adc3b9ca39cb5e75445346f663610d2f19b93 [mark-control-plane] Marking the node k8smaster as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node k8smaster as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule] [bootstrap-token] Using token: xemboe.350o69u6adf5oor6 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy</p> <p>Your Kubernetes control-plane has initialized successfully!</p> <p>To start using your cluster, you need to run the following as a regular user:</p> <p>mkdir -p $HOME/.kube   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config   sudo chown $(id -u):$(id -g) $HOME/.kube/config</p> <p>Alternatively, if you are the root user, you can run:</p> <p>export KUBECONFIG=/etc/kubernetes/admin.conf</p> <p>You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:   https://kubernetes.io/docs/concepts/cluster-administration/addons/</p> <p>You can now join any number of control-plane nodes running the following command on each as root:</p> <p>kubeadm join k8smaster:6443 --token xemboe.350o69u6adf5oor6 \\     --discovery-token-ca-cert-hash sha256:dc5594506fa9daed6732acaaa766d5d672ceae4c0918a5b06c572d9e715303d8 \\     --control-plane --certificate-key 289aead532d1508800f44452a24adc3b9ca39cb5e75445346f663610d2f19b93</p> <p>Please note that the certificate-key gives access to cluster sensitive data, keep it secret! As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward.</p> <p>Then you can join any number of worker nodes by running the following on each as root:</p> <p>kubeadm join k8smaster:6443 --token xemboe.350o69u6adf5oor6 \\     --discovery-token-ca-cert-hash sha256:dc5594506fa9daed6732acaaa766d5d672ceae4c0918a5b06c572d9e715303d8 </p> <p>Errors:</p> <p>can run the init command twice ![[Pasted image 20250212122209.png]]</p> <p>error while ![[Pasted image 20250211165637.png]]</p> <p>]]![[Pasted image 20250212094920.png]]</p> <p>take way : in worker node kubelet service will not start until an unless if it hasnot yet joined the master node ![[Pasted image 20250212120421.png]]</p> <p>Node has successfully joined the master kubeadm join 192.168.17.17:6443 --token pq28mb.2c5zbijfao4pupxe \\         --discovery-token-ca-cert-hash sha256:5a66c8b27002ab5b6ba55a81f02446525120464a43f373b1c1b85d164de9857f</p> <p>![[Pasted image 20250212143609.png]]</p> <p>command executed in master node:</p> <p>kubeadm init --apiserver-advertise-address=192.168.17.17 --pod-network-cidr=192.168.0.0/16  --ignore-preflight-errors=all</p> <pre><code>\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action beforehand using 'kubeadm config images pull'\nW0212 08:42:29.652370    1978 checks.go:846] detected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm.It is recommended to use \"registry.k8s.io/pause:3.10\" as the CRI sandbox image.\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8smaster kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.17.17]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8smaster localhost] and IPs [192.168.17.17 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8smaster localhost] and IPs [192.168.17.17 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"super-admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\"\n[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s\n[kubelet-check] The kubelet is healthy after 1.002363517s\n[api-check] Waiting for a healthy API server. This can take up to 4m0s\n[api-check] The API server is healthy after 7.501763839s\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node k8smaster as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8smaster as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]\n[bootstrap-token] Using token: pq28mb.2c5zbijfao4pupxe\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\n</code></pre> <p>![[Pasted image 20250212143722.png]]</p> <p>getting error even after joining the master</p> <p>kubelet get nodes in worker node: ![[Pasted image 20250212143943.png]]</p> <p>this error in master</p> <p>kubectl get nodes The connection to the server 192.168.17.17:6443 was refused - did you specify the right host or port?</p> <p>this issue was solved after changing in :</p> <p>reset the containerd by using : containerd config default &gt; /etc/containerd/config.toml ![[Pasted image 20250212160742.png]]</p> <p>coredns status pending (not yet install calico network) ![[Pasted image 20250213105651.png]]</p> <p>After doing the calico installation usign the below command https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart</p> <ol> <li>kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml</li> <li> <p>kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/custom-resources.yaml</p> </li> <li> <p>watch kubectl get pods -n calico-system</p> </li> </ol> <p>![[Pasted image 20250213112342.png]] ![[Pasted image 20250213112403.png]]</p> <p>HELM: </p> <pre><code>    export NODE_PORT=$(kubectl get --namespace portainer -o jsonpath=\"{.spec.ports[0].nodePort}\" services portainer)\n  export NODE_IP=$(kubectl get nodes --namespace portainer -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n  echo https://$NODE_IP:$NODE_PORT\n\n</code></pre> <p>Issue related to cri-containerd after reboot /poweroff</p> <p>![[Pasted image 20250214102737.png]]</p> <p>didnot add this modprobe modules and even working </p> <p>sudo tee /etc/modules-load.d/containerd.conf &lt;&lt;EOF overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter</p>"},{"location":"K8s-cluster%20Initial%20Setup%20using%20bash/","title":"note 1","text":"<pre><code>#!/bin/bash\n\n#Bash script for k8s cluster setup using kubeadm on Linux OS\n\n\nLINUXOS=`cat /etc/os-release | awk -F'=' '/^ID=/ { print $2 }'|tr -d '\"'`\nVCPU=`nproc`\nVMEM=`cat /proc/meminfo |awk '/MemTotal/ {printf \"%.1f GB\", $2/1024/1024}'` \nHOSTNAME=`hostname`\nMAC_ADDRESS=`cat /sys/class/net/$(ip route | awk '/default/ {print $5}')/address`\nPRODUCT_ID=`cat /sys/class/dmi/id/product_uuid`\n\nif [ `id -u` -ne 0 ];then\n\n  echo \"Please run the script as root user!!!\"\n  exit 0\nfi\nbanner_info() {\n\n  echo \"##################################################\"\n  echo \"Distro: $LINUXOS\"\n  echo \"vCPU: $VCPU\"\n  echo \"vMem: $VMEM\"\n  echo \"HostName: $HOSTNAME\"\n  echo \"Mac Address: $MAC_ADDRESS\"\n  echo \"Product Id: $PRODUCT_ID\"\n  echo \"###################################################\"\n}\n\nsystem_update() {\n    if [ \"$LINUXOS\" == \"almalinux\" ];then\n        echo -e \"\\n[+]Updating $LINUXOS... \\n\"\n        dnf update -y\n    else \n        echo -e \"\\n[+]Updating $LINUXOS...\\n\"\n        apt update -y\n    fi\n}\n\ndisable_security() {\n    if [ \"$LINUXOS\" == \"almalinux\" ];then\n        setenforce 0\n        sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config\n    else\n        systemctl disable apparmor --now\n        ufw disable\n    fi\n}\n\n\nconfig_swap() {\n    echo -e \"\\n[*]Checking swap...\\n\"\n    if swapon -s || cat /etc/fstab|grep \"swap\";then\n        echo -e \"\\n Swap found; Removing it...\\n\"\n        swapoff -a\n        sed -i '/swap/d' /etc/fstab\n    else\n        echo -e \"\\n[+]No swap found.\\n\"\n    fi\n}\n\nsysctl_config() {\n    cat &lt;&lt;-EOF | sudo tee /etc/sysctl.d/k8s.conf\n    net.ipv4.ip_forward = 1\n    net.bridge.bridge-nf-call-ip6tables = 1\n    net.bridge.bridge-nf-call-iptables = 1\n    EOF\n    echo -e \"\\n[+]Applying conf...\\n\"\n    sysctl --system 1&gt; /dev/null\n}\n\nkernel_modules() {\n    if lsmod | grep \"overlay\" 1&gt; /dev/null &amp;&amp; lsmod | grep \"br_netfilter\" 1&gt; /dev/null;then\n        echo -e \"[*] Already Exists.\\n\"\n    else\n        modprobe overlay\n        modprobe br_netfilter\n    fi\n}\n\ndocker_remove() {\n    if [ \"$LINUXOS\" == \"almalinux\" ];then\n        echo -e \"\\n[+]Removing docker package in almalinux...\\n\"\n        for pkg in docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine;do\n            dnf remove $pkg;\n        done\n    else\n        echo -e \"\\n[+]Removing docker package in Ubuntu...\\n\"\n        for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc;do\n            apt remove $pkg;\n        done\n    fi\n}\n\nupdate_repo() {\n    if [ \"$LINUXOS\" == \"almalinux\" ];then\n        echo -e \"\\n[+]Installing Docker Repo in almalinux...\"\n        dnf -y install dnf-plugins-core\n        dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n    else\n        echo -e \"[+]Insalling Docker Repo in Ubuntu...\\n\"\n        # Add Docker's official GPG Key:\n        apt-get update\n        apt-get install ca-certificates curl\n        install -m 0755 -d /etc/apt/keyrings\n        curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n        chmod a+r /etc/apt/keyrings/docker.asc\n        # Add the repository to Apt sources:\n        echo \\\n            \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n            $(. /etc/os-release &amp;&amp; echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" | \\\n            tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n        apt update\n    fi\n}\n\ninstall_docker() {\n    if [ \"$LINUXOS\" == \"almalinux\" ];then\n        echo -e \"\\n[+]Installing Docker on almalinux\\n\"\n        dnf install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n        systemctl enable docker --now\n    else\n        echo -e \"\\n[+]Installing Docker on Ubuntu\\n\"\n        apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n        systemctl enable docker --now\n    fi\n}\n\ninstall_k8s_repo() {\n    if [ \"$LINUXOS\" == \"ubuntu\" ];then\n        apt update\n        apt install -y apt-transport-https ca-certificates curl gpg\n        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list\n    else\n        cat &lt;&lt;-EOF | sudo tee /etc/yum.repos.d/kubernetes.repo\n        [kubernetes]\n        name=Kubernetes\n        baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/\n        enabled=1\n        gpgcheck=1\n        gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key\n        exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni\n        EOF\n    fi\n}\n\ninstall_k8s_pkg() {\n    if [ \"$LINUXOS\" == \"ubuntu\" ];then\n        echo -e \"\\n[+]Installing k8s package in ubuntu...\\n\"\n        apt update\n        apt install -y kubelet kubeadm kubectl\n        apt-mark hold kubelet kubeadm kubectl\n        systemctl enable --now kubelet\n\n    else\n        echo -e \"\\n[+]Installing k8s pacakge in almalinux...\\n\"\n        yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n        systemctl enable --now kubelet\n    fi\n}\n\nconfig_cgroup() {\n    echo -e \"\\n[+]adding Cgroup to systemd...\\n\"\n    containerd config default &gt; /etc/containerd/config.toml\n    sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml\n    systemctl restart containerd\n}\n\nbanner_info\nsystem_update\ndisable_security\nconfig_swap\nsysctl_config\nkernel_modules\ndocker_remove\nupdate_repo\ninstall_docker\ninstall_k8s_repo\ninstall_k8s_pkg\nconfig_cgroup\n</code></pre>"}]}